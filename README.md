# IPLData_DataEngineering_Project_Pyspark_Databricks
IPL Data Analytics with AWS S3 + Databricks + PySpark

# ğŸ IPL Data Analytics using AWS S3, Databricks, and PySpark

This project demonstrates a complete end-to-end data engineering and analytics pipeline for analyzing **Indian Premier League (IPL)** cricket data. It utilizes cloud-native services and big data technologies to process, clean, and prepare rich cricket datasets for future analytical and machine learning use cases.

---

## ğŸ“ Dataset Source

The dataset was downloaded from [[Data.World â€“ IPL Dataset](https://data.world/](https://data.world/raghu543/ipl-data-till-2017/workspace/data-dictionary)) and includes the following CSV files:

| File Name            | Description                                          |
|----------------------|------------------------------------------------------|
| `Ball_By_Ball.csv`   | Ball-by-ball level data for each IPL match          |
| `Match.csv`          | Match-level details, including venue, results       |
| `Player.csv`         | Player demographic and skill information            |
| `Player_match.csv`   | Player-level statistics for each match              |
| `Team.csv`           | Team identifiers and names                          |

---

## â˜ï¸ Cloud Infrastructure

- **AWS S3**: Used as the storage layer to upload and host all raw CSV files.
- **Databricks**: Used as the compute and data processing environment.
- **PySpark**: Used for schema definitions, data ingestion, transformation, and exploration.

---

## ğŸ”§ Technologies Used

- ğŸ Python
- ğŸ”¥ Apache Spark (PySpark)
- â˜ï¸ AWS S3
- ğŸ§  Databricks Notebook
- ğŸ“Š Structured Streaming (optional for real-time extensions)

---

## ğŸ“Œ Project Structure
IPL_Data_Analysis_Spark.ipynb
Read.me
Data


